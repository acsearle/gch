



namespace gch {
    
    // The Garbage Collection Handbook
    
    enum Color {
        WHITE, // not marked
        GRAY,  // marked and in worklist
        BLACK, // marked and not in worklist
    };
    
    struct Object {
        Color color = WHITE;
        Object* next = nullptr; // All Objects as an implicit linked list
        Object* slots[8] = {};
    };
    
    bool isWhite(Object* object) {
        return object->color == WHITE;
    }
    
    bool isGray(Object* object) {
        return object->color == GRAY;
    }
    
    bool isBlack(Object* object) {
        return object->color == BLACK;
    }
    
    bool isMarked(Object* objects) {
        return !isWhite(objects);
    }
    
    Object* Read(Object* src, int i) {
        return src->slots[i];
    }
    
    void Write(Object* src, int i, Object* ref) {
        src->slots[i] = ref;
    }
    
    intptr_t count = 0;
    
    Object* head = nullptr; // all allocated objects chain from this
    
    Object* allocate() {
        Object* ref = new Object;
        assert(ref);
        ref->next = head;
        head = ref;
        ++count;
        return ref;
    }
    
    void free(Object* ref) {
        assert(ref);
        delete ref;
        --count;
    }
    
    std::vector<Object*> roots;
    std::vector<Object*> worklist;
    
    void revert(Object* ref) {
        assert(isBlack(ref));
        ref->color = GRAY;
        worklist.push_back(ref);
    }
    
    void shade(Object* ref) {
        if (isWhite(ref)) {
            ref->color = GRAY;
            worklist.push_back(ref);
        }
    }
    
    void scan(Object* ref) {
        assert(isBlack(ref));
        for (Object* child : ref->slots)
            if (child)
                shade(child);
    }
    
    void mark() {
        while (!worklist.empty()) {
            Object* ref = worklist.back();
            assert(isGray(ref));
            worklist.pop_back();
            ref->color = BLACK;
            for (Object* child : ref->slots)
                if (child)
                    shade(child);
        }
    }
    
    void markFromRoots() {
        assert(worklist.empty());
        for (Object* ref : roots) {
            if (ref && isWhite(ref)) {
                ref->color = GRAY;
                worklist.push_back(ref);
                mark(); // depth first traversal of roots
            }
        }
    }
    
    void sweep() {
        Object** next = &head;
        while (*next) {
            Object* object = *next;
            switch (object->color) {
                case WHITE:
                    *next = object->next;
                    free(object);
                    break;
                case GRAY:
                    abort();
                case BLACK:
                    object->color = WHITE;
                    next = &object->next;
            }
        }
    }
    
    void scanRoots() {
        for (Object* ref : roots) {
            if (ref && isWhite(ref)) {
                ref->color = GRAY;
                worklist.push_back(ref);
            }
        }
    }
    
    bool markSome() {
        if (worklist.empty()) {
            scanRoots();
            if (worklist.empty()) {
                sweep();
                return false;
            }
        }
        Object* ref = worklist.back();
        worklist.pop_back();
        ref->color = BLACK;
        scan(ref);
        return true;
    }
    
    void WriteSteele(Object* src, int i, Object* ref) {
        src->slots[i] = ref;
        if (isBlack(src))
            if (isWhite(ref))
                revert(src);
    }
    
    void WriteBoehm(Object* src, int i, Object* ref) {
        src->slots[i] = ref;
        if (isBlack(src))
            revert(src);
    }
    
    void WriteDijkstra(Object* src, int i, Object* ref) {
        src->slots[i] = ref;
        if (isBlack(src))
            shade(ref);
    }
    
    
    void mutate() {
        printf("mutating %zd", gch::count);
        for (;;) {
            if (!(rand() % 100))
                // yield
                break;
            if (!(rand() % 11)) {
                // erase root
                if (!roots.empty()) {
                    int i = rand() % roots.size();
                    roots.erase(roots.begin() + i);
                    continue;
                }
            }
            if (!(rand() % 10)) {
                // add root
                Object* ref = allocate();
                roots.push_back(ref);
                continue;
            }
            if (!roots.empty()) {
                // choose root
                Object* ref = roots[rand() % roots.size()];
                while (ref) {
                    // choose slot
                    int i = rand() % 8;
                    if (!(rand() % 8)) {
                        // clear slot
                        Write(ref, i, nullptr);
                        continue;
                    }
                    if (!(rand() % 4)) {
                        // overwrite slot
                        Write(ref, i, allocate());
                        continue;
                    }
                    // recurse slot
                    ref = Read(ref, i);
                }
            }
        }
        printf(" -> %zd", gch::count);
    }
    
    void collect() {
        printf("collecting %zd", gch::count);
        markFromRoots();
        sweep();
        printf(" -> %zd", gch::count);
    }
}


void exercise() {
    printf("start");
    gch::collect();
    for (int i = 0; i != 100; ++i) {
        gch::mutate();
        gch::collect();
    }
    printf("clearing roots");
    gch::roots.clear();
    gch::collect();
}

namespace gch2 {
    
    // The Garbage Collection Handbook
    
    // Concurrent collector with a single mutator thread and a single collector
    // thread
    
    enum Color : intptr_t {
        WHITE,
        GRAY,
        BLACK,
        
        YELLOW,
    };
    
    // we don't actually need gray or yellow?
    
    struct alignas(64) Object {
        intptr_t color; // only touched by GC thread (!)
        std::atomic<Object*> slots[7];
    };
    
    
    struct Epoch {
        std::vector<Object*> roots;
        std::vector<Object*> victims;
        std::vector<Object*> infants;
    };
    
    std::mutex epoch_queue_mutex;
    std::condition_variable epoch_queue_condition_variable;
    std::deque<Epoch> epoch_queue;
    
    void publish(Epoch epoch) {
        {
            std::unique_lock<std::mutex> lock(epoch_queue_mutex);
            epoch_queue.push_back(std::move(epoch));
        }
        epoch_queue_condition_variable.notify_one();
        
    }
    
    void mutate() {
        std::vector<Object*> roots;
        Epoch epoch;
        int allocated = 0;
        
        auto allocate = [&]() -> Object* {
            Object* object = new Object;
            epoch.infants.push_back(object);
            ++allocated;
            return object;
        };
        
        auto read = [&epoch](Object* object, int i) -> Object* {
            return object->slots[i].load(std::memory_order_relaxed);
        };
        
        auto write = [&epoch](Object* object, int i, Object* ref) {
            Object* victim = object->slots[i].exchange(ref, std::memory_order_release);
            if (victim)
                epoch.victims.push_back(victim);
        };
        
        for (;;) {
            // copy the true roots
            epoch.roots = roots;
            assert(epoch.victims.empty());
            assert(epoch.infants.empty());
            
            // now mutate the graph freely for a while, subject to the
            // following "taxes"
            // record overwritten pointers in victims
            // record new allocations in infants
            
            if (roots.empty()) {
                roots.push_back(allocate());
            }
            
            // this is not doing the hard case of erase and reinsert
            
            Object* object = nullptr;
            for (int i = 0; i != 1000; ++i) {
                if (!object)
                    object = roots.back();
                int j = rand() % 7;
                switch (rand() % 3) {
                    case 0: {
                        object = read(object, j);
                        break;
                    }
                    case 1: {
                        write(object, j, allocate());
                        break;
                    }
                    case 2: {
                        write(object, j, nullptr);
                        break;
                    }
                }
            }
            
            publish(std::move(epoch));
            printf("allocated %d", allocated);
        }
    }
    
    void collect() {
        
        Epoch epoch;
        std::vector<Object*> nodes; // all objects
        std::vector<Object*> worklist; // gray objects
        int freed = 0;
        
        for (;;) {
            {
                std::unique_lock<std::mutex> lock(epoch_queue_mutex);
                while (epoch_queue.empty()) {
                    epoch_queue_condition_variable.wait(lock);
                }
                epoch = std::move(epoch_queue.front());
                epoch_queue.pop_front();
            }
            // We now have
            // - the roots at the beginning of the epoch
            // - the original value of any pointers overwritten during the epoch
            // - the pointers allocated during the epoch
            
            // We already know all objects that survived the previous
            // collection, and the roots will be a subset of these
            
            // For multi-threading, we need to construct a consensus epoch
            // for which the beginning of every thread's epoch is before the
            // end of every thread's epoch; see crossbeam's epochs.  Basically
            // we don't advance until every thread has checked in on the epoch
            
            for (Object* object : epoch.roots) {
                if (object->color == WHITE) {
                    object->color = GRAY;
                    worklist.push_back(object);
                }
            }
            epoch.roots.clear();
            
            for (Object* object : epoch.victims) {
                if (object->color == WHITE) {
                    object->color = GRAY;
                    worklist.push_back(object);
                }
            }
            epoch.victims.clear();
            
            // trace
            while (!worklist.empty()) {
                Object* object = worklist.back();
                assert(object->color == GRAY);
                object->color = BLACK;
                worklist.pop_back();
                
                for (std::atomic<Object*>& slot : object->slots) {
                    // Acquire because we will dereference the pointer and it
                    // may have changed after the epoch closed
                    Object* p = slot.load(std::memory_order_acquire);
                    if (p && object->color == WHITE) {
                        // WHITE  -> needs to be traced
                        // GRAY   -> is already in the worklist
                        // BLACK  -> is already traced
                        // YELLOW -> can only hold yellow or alternatively reached objects
                        worklist.push_back(p);
                    }
                }
            }
            
            // sweep
            {
                auto a = nodes.begin();
                auto b = a;
                auto c = nodes.end();
                while (b != c) {
                    Object* object = *b;
                    switch (object->color) {
                            
                        case WHITE: {
                            free(object);
                            ++freed;
                            ++b;
                            break;
                        }
                            
                        case BLACK: {
                            object->color = WHITE;
                            *a = *b;
                            ++a;
                            ++b;
                            break;
                        }
                            
                        default: {
                            abort();
                        }
                            
                    };
                }
                nodes.erase(a, c);
            }
            
            printf("freed %d", freed);
            
            // promote
            for (Object* object : epoch.infants) {
                object->color = WHITE;
                nodes.push_back(object);
            }
            
        }
    }
    
    
    void exercise2() {
        std::thread collector(gch2::collect);
        std::thread mutator(gch2::mutate);
        mutator.join();
        collector.join();
    }
    
    
}




        
        // Steele
        //
        // Causes rescan.  The original value is already traced.  The new
        // value will be traced unless it is overwritten again before the
        // tracing completes.
        //
        // Causes BLACK -> GRAY transitions
        //
        // Conservatively retains some of the intermediate values of src[i]
        //
        // Terminates when the mutators can no longer access any WHITE values
        // to write, i.e. we have MARKED all live objects.
        //
        //  src[i] <- ref;
        //  if isBlack(src)
        //      if isWhite(ref)
        //          revert(src)
        /*
        src->slots[i].store(ref, std::memory_order_release);
        if (ref && ref->color.load(std::memory_order_relaxed) == WHITE) {
            std::unique_lock lock(mutex);
            Color expected = BLACK;
            Color desired = GRAY;
            if (src->color.compare_exchange_strong(expected, desired, std::memory_order_acquire, std::memory_order_relaxed)) {
                worklist.push_back(src);
            }
        }
         */

        // Boehm
        //
        // Unconditionally rescans after any write.  Termination needs to
        // prevent these writes for long enough to trace all the GRAY.
        //
        //  src[i] <- ref
        //  if isBlack(src)
        //      revert(src)
        /*
        std::unique_lock lock(mutex);
        Color expected = BLACK;
        Color desired = GRAY;
        if (src->color.compare_exchange_strong(expected, desired, std::memory_order_acquire, std::memory_order_relaxed)) {
            worklist.push_back(src);
        }
         */

        // Djikstra
        //
        // Never rescans so there is a progress guarantee.
        //
        //  src[i] <- ref
        //  if isBlack(src)
        //     shade(ref)
        /*
        if (ref && src->color.load(std::memory_order_relaxed) == BLACK) {
            std::unique_lock lock(mutex);
            Color expected = WHITE;
            Color desired = GRAY;
            ref->color.compare_exchange_strong(expected, desired, std::memory_order_release, std::memory_order_relaxed);
        }
         */
        
        // Yuasa
        //
        // if not isBlack(src)
        //     shade(src[i]
        // src[i] <- ref
        
        // Unconditional delete barrier
        //
        // Has the interesting property that the retained set is actually well
        // defined, as everything that was reachable at any point during the
        // mark stage will be retained.
        //
        // shade(src[i])
        // src[i] <- ref


   Object* Read(Object* src, std::size_t i) {
        assert(src);
        assert(i < SLOTS);
        // The mutator thread is already ordered wrt the fields
        return src->slots[i].load(std::memory_order_relaxed);
    }
        
    
    void Write(Object* src, std::size_t i, Object* ref, bool* dirty) {
        assert(src);
        assert(i < SLOTS);
        // src is reachable, because the mutator reached it
        // ref is reachable (or nullptr), because the mutator reached it

        
        if (Object* old = src->slots[i].exchange(ref, std::memory_order_release)) {
            // old was reachable, because the mutator just reached it
            
            // The store is RELEASE because the collector will dereference the
            // pointer so writes to its Object must happen-before the store
            
            // The load part is RELAXED because the mutator itself perfomed the
            // original store
            
            // src may be BLACK and ref may be WHITE; we have just violated
            // the strong tricolor invariant
            
            // old may have been part of the chain by which such a WHITE ref
            // was reached, so we GRAY it; we have just preserved the weak
            // tricolor invariant
            
            Mark expected = UNMARKED;
            if (old->mark.compare_exchange_strong(expected,
                                                  MARKED,
                                                  std::memory_order_relaxed,
                                                  std::memory_order_relaxed)) {
                // We race the collector to transition old from UNMARKED:WHITE
                // to MARKED:GRAY.
                
                // Memory order is relaxed because no memory is published by
                // this operation.  Synchronization is ultimately achieved via
                // the handshake.
                
                assert(expected == UNMARKED);
                *dirty = true;
                
                // When the collector is unable to find any GRAY items, it
                // rendevous with each thread and clears the dirty flag.
                //
                // If the collector saw any set flag, it must scan again for
                // GRAY items.
                //
                // Dirty assists in discovering GRAYs made between the
                // collector's last inspection of a white object, and the
                // handshake.
                //
                // The mutator can only produce GRAY objects by reaching
                // WHITE objects, so it can no longer produce GRAY when the
                // scan is actually complete.
                //
                // Allowed operations are 
                // - WHITE -> GRAY, performed by both the mutator and collector
                // - GRAY -> BLACK, performed only by the collector
                // - allocate BLACK, performed only by the mutator
                // so we cannot run indefinitely; in fact we can do only
                // do up to the initial number of WHITE objects of each
                // transition, so we will terminate.
                //
                // Newly allocated BLACK objects are of no interest to the
                // mark phase.  We can incorporate them en masse when we
                // sweep.
                

            } else {
                assert(expected == MARKED);
            }
        }

    }



    enum Color : intptr_t {
        WHITE,
        GRAY,
        BLACK,
    };
    
    constexpr const char* ColorNames[3] = {
        [WHITE] = "WHITE",
        [GRAY] = "GRAY",
        [BLACK] = "BLACK",
    };




 struct TestObject : Object {
        
        Slot<TestObject> slots[SLOTS];
        
        virtual ~TestObject() override = default;
        [[nodiscard]] virtual std::size_t _gc_scan() const override;
        
    };
    
    // When the collector scans an object it may see any of the values a slot
    // has taken on since the last handshake
    
    // The collector must load-acquire the pointers because of the ordering
    // - handshake
    // - mutator allocates A
    // - mutator writes A into B[i]    RELEASE
    // - collector reads B[i]          ACQUIRE
    // - collector dereferences A
    
    std::size_t TestObject::_gc_scan() const {
        std::size_t count = 0;
        for (const auto& slot : slots)
            if (Object::_gc_shade(slot.load(std::memory_order_acquire)))
                ++count;
        return count;
    }
    
    
    
    
    
    std::vector<TestObject*> nodesFromRoot(TestObject* root) {
        std::set<TestObject*> set;
        std::vector<TestObject*> vector;
        vector.push_back(root);
        set.emplace(root);
        for (int i = 0; i != vector.size(); ++i) {
            TestObject* src = vector[i];
            for (int j = 0; j != SLOTS; ++j) {
                TestObject* ref = src->slots[j].load();
                if (ref) {
                    auto [_, flag] = set.insert(ref);
                    if (flag) {
                        vector.push_back(ref);
                    }
                }
            }
        }
        return vector;
    }
    
    std::pair<std::set<TestObject*>, std::set<std::pair<TestObject*, TestObject*>>> nodesEdgesFromRoot(TestObject* root) {
        std::set<TestObject*> nodes;
        std::set<std::pair<TestObject*, TestObject*>> edges;
        std::stack<TestObject*> stack;
        stack.push(root);
        nodes.emplace(root);
        while (!stack.empty()) {
            TestObject* src = stack.top();
            stack.pop();
            for (int i = 0; i != SLOTS; ++i) {
                TestObject* ref = src->slots[i].load();
                if (ref) {
                    auto [_, flag] = nodes.insert(ref);
                    if (flag) {
                        stack.push(ref);
                    }
                    edges.emplace(src, ref);
                }
            }
        }
        return std::pair(std::move(nodes), std::move(edges));
    }
    
    void printObjectGraph(TestObject* root) {
        
        auto [nodes, edges] = nodesEdgesFromRoot(root);
        
        std::map<TestObject*, int> labels;
        int count = 0;
        for (TestObject* object : nodes) {
            labels.emplace(object, count++);
        }

        printf("%zu nodes", nodes.size());
        printf("%zu edges", edges.size());
        for (auto [a, b] : edges) {
            printf("  (%d) -> (%d)", labels[a], labels[b]);
        }
    }
    
    
    
    
    void mutate() {
                
        size_t allocated = 0;
        
        std::vector<TestObject*> local_roots;
        bool local_dirty = true;
        std::vector<Object*> local_infants;
        
        auto allocate = [&local_infants]() -> TestObject* {
            TestObject* infant = new TestObject();
            local_infants.push_back(infant);
            return infant;
        };
        
        local_roots.push_back(allocate());

        std::vector<TestObject*> nodes;
        nodes = nodesFromRoot(local_roots.back());
                
        for (;;) {

            // Handshake
            
            {
                bool pending;
                bool collector_dirty = false;
                {
                    std::unique_lock lock(channel.mutex);
                    pending = channel.pending;
                    if (pending) {
                        
                        collector_dirty = channel.dirty;

                        if (channel.dirty)
                            local_dirty = true;
                        channel.dirty = local_dirty;
                        local_dirty = false;
                        
                        if (channel.dirty) {
                            local_dirty = true;
                        } else {
                            channel.dirty = local_dirty;
                        }

                        assert(channel.objects.empty());
                        channel.objects.swap(local_infants);
                        assert(local_infants.empty());

                        channel.pending = false;
                    }
                }
                if (pending) {
                    channel.condition_variable.notify_all();
                }

                if (collector_dirty) {
                    for (TestObject* ref : local_roots)
                        if (Object::_gc_shade(ref))
                            local_dirty = true;
                }
                

            }

            
            printf("Total objects allocated %zd", allocated);
            // do some graph work
            
            for (int i = 0; i != 100; ++i) {
                
                assert(!nodes.empty()); // we should at least have the root
                
                // choose two nodes and a slot
                int j = rand() % nodes.size();
                int k = rand() % SLOTS;
                int l = rand() % nodes.size();
                TestObject* p = nullptr;
                
                if (nodes.size() < rand() % 100) {
                    // add a new node
                    p = allocate();
                    ++allocated;
                } else if (nodes.size() < rand() % 100) {
                    // add a new edge betweene existing nodes
                    p = nodes[l];
                }
                // Write(nodes[j], k, p, &local_dirty);
                if (nodes[j]->slots[k].store(p))
                    local_dirty = true;
                // Whatever we wrote may have overwritten an existing edge
                
                nodes = nodesFromRoot(local_roots.back());
                
                // printObjectGraph(roots.back());
                
            }
            
            
        }
    }
    

     constexpr std::size_t SLOTS = 6;
    
    struct TestObject : Object {
        
        Slot<TestObject> slots[SLOTS];
        
        virtual ~TestObject() override = default;
        [[nodiscard]] virtual std::size_t _gc_scan() const override;
        
    };
    
    // When the collector scans an object it may see any of the values a slot
    // has taken on since the last handshake
    
    // The collector must load-acquire the pointers because of the ordering
    // - handshake
    // - mutator allocates A
    // - mutator writes A into B[i]    RELEASE
    // - collector reads B[i]          ACQUIRE
    // - collector dereferences A
    
    std::size_t TestObject::_gc_scan() const {
        std::size_t count = 0;
        for (const auto& slot : slots)
            if (Object::_gc_shade(slot.load(std::memory_order_acquire)))
                ++count;
        return count;
    }



    std::vector<TestObject*> nodesFromRoot(TestObject* root) {
        std::set<TestObject*> set;
        std::vector<TestObject*> vector;
        vector.push_back(root);
        set.emplace(root);
        for (int i = 0; i != vector.size(); ++i) {
            TestObject* src = vector[i];
            for (int j = 0; j != SLOTS; ++j) {
                TestObject* ref = src->slots[j].load();
                if (ref) {
                    auto [_, flag] = set.insert(ref);
                    if (flag) {
                        vector.push_back(ref);
                    }
                }
            }
        }
        return vector;
    }
    
    std::pair<std::set<TestObject*>, std::set<std::pair<TestObject*, TestObject*>>> nodesEdgesFromRoot(TestObject* root) {
        std::set<TestObject*> nodes;
        std::set<std::pair<TestObject*, TestObject*>> edges;
        std::stack<TestObject*> stack;
        stack.push(root);
        nodes.emplace(root);
        while (!stack.empty()) {
            TestObject* src = stack.top();
            stack.pop();
            for (int i = 0; i != SLOTS; ++i) {
                TestObject* ref = src->slots[i].load();
                if (ref) {
                    auto [_, flag] = nodes.insert(ref);
                    if (flag) {
                        stack.push(ref);
                    }
                    edges.emplace(src, ref);
                }
            }
        }
        return std::pair(std::move(nodes), std::move(edges));
    }
    
    void printObjectGraph(TestObject* root) {
        
        auto [nodes, edges] = nodesEdgesFromRoot(root);
        
        std::map<TestObject*, int> labels;
        int count = 0;
        for (TestObject* object : nodes) {
            labels.emplace(object, count++);
        }

        printf("%zu nodes", nodes.size());
        printf("%zu edges", edges.size());
        for (auto [a, b] : edges) {
            printf("  (%d) -> (%d)", labels[a], labels[b]);
        }
    }
    
    

        
        // TODO:
        // we need a mechanism for a thread to suspend without jamming the
        // collector; a thread that is asleep won't make any GRAY, but
        // neither can we ask it to export its roots
        
        // should the roots just live in the channel, and the collector is
        // responsible for scanning them when needed?  Or just one global root?
        // The notion of thread-specific roots is mainly for atomatically
        // tracing stack variables
        // which we can't support
        
        
